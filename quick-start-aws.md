# Quick Start Guide - AWS Deployment

æœ€å¿«é€Ÿçš„AWSéƒ¨ç½²æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰

## ğŸš€ 30åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²

### å‡†å¤‡å·¥ä½œï¼ˆåœ¨æœ¬åœ°å®Œæˆï¼‰

1. **ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²è§£å‹**
   ```bash
   cd backend/ml_models
   ls deployment_package/models/sbi/exp003_best_model.pth
   ls deployment_package/models/distildire/v2_best_model.pth
   ```

2. **Pushä»£ç åˆ°GitHub**
   ```bash
   git add .
   git commit -m "Prepare for AWS deployment with all models"
   git push origin main
   ```

### AWSéƒ¨ç½²ï¼ˆåœ¨EC2ä¸Šå®Œæˆï¼‰

#### æ­¥éª¤1: å¯åŠ¨EC2å®ä¾‹

åœ¨AWS Consoleä¸­:
1. è¿›å…¥ EC2 Dashboard
2. ç‚¹å‡» "Launch Instance"
3. é€‰æ‹©é…ç½®:
   - **Name**: deepfake-detection
   - **AMI**: Ubuntu Server 22.04 LTS æˆ– Deep Learning AMI (å¦‚æœéœ€è¦GPU)
   - **Instance type**:
     - å¼€å‘/æµ‹è¯•: `t3.xlarge` (4 vCPU, 16GB RAM) - $0.17/hour
     - ç”Ÿäº§/GPU: `g4dn.xlarge` (4 vCPU, 16GB RAM, NVIDIA T4) - $0.53/hour
   - **Storage**: 50GB
   - **Security Group**: å¼€æ”¾ç«¯å£ 22 (SSH), 80 (HTTP), 443 (HTTPS)
4. ä¸‹è½½key pairå¹¶å¯åŠ¨å®ä¾‹

#### æ­¥éª¤2: SSHè¿æ¥åˆ°EC2

```bash
# åœ¨æœ¬åœ°ç”µè„‘è¿è¡Œ
chmod 400 your-key.pem
ssh -i your-key.pem ubuntu@<EC2-PUBLIC-IP>
```

#### æ­¥éª¤3: å…‹éš†ä»“åº“

```bash
# åœ¨EC2ä¸Šè¿è¡Œ
git clone https://github.com/your-username/COSC449_hybrid-deepfake-detection.git
cd COSC449_hybrid-deepfake-detection
```

#### æ­¥éª¤4: ä¸Šä¼ æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœæ¨¡å‹æ²¡æœ‰pushåˆ°gitï¼‰

**é€‰é¡¹A: ä»æœ¬åœ°ä¸Šä¼ ï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£ï¼‰**
```bash
# åœ¨æœ¬åœ°ç”µè„‘è¿è¡Œ
scp -i your-key.pem backend/ml_models/deepfake_deployment.tar.gz ubuntu@<EC2-PUBLIC-IP>:~/COSC449_hybrid-deepfake-detection/backend/ml_models/

# å›åˆ°EC2ç»ˆç«¯ï¼Œè§£å‹
cd backend/ml_models
tar -xzf deepfake_deployment.tar.gz
cd ../..
```

**é€‰é¡¹B: ä»S3ä¸‹è½½ï¼ˆå¦‚æœä¸Šä¼ åˆ°äº†S3ï¼‰**
```bash
# åœ¨EC2ä¸Šè¿è¡Œ
aws s3 cp s3://your-bucket/deepfake_deployment.tar.gz backend/ml_models/
cd backend/ml_models && tar -xzf deepfake_deployment.tar.gz && cd ../..
```

#### æ­¥éª¤5: é…ç½®ç¯å¢ƒå˜é‡

```bash
# åˆ›å»º.envæ–‡ä»¶
cat > backend/.env << EOF
OPENAI_API_KEY=sk-your-actual-openai-api-key-here
MODEL_SBI_PATH=/app/ml_models/deployment_package/models/sbi
MODEL_DISTILDIRE_PATH=/app/ml_models/deployment_package/models/distildire
EOF
```

#### æ­¥éª¤6: ä¸€é”®éƒ¨ç½²

```bash
# è¿è¡Œè‡ªåŠ¨éƒ¨ç½²è„šæœ¬
./deploy-aws.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨:
- âœ… å®‰è£…Dockerå’ŒDocker Compose
- âœ… æ£€æµ‹å¹¶é…ç½®GPU (å¦‚æœæœ‰)
- âœ… æ„å»ºDockeré•œåƒ
- âœ… å¯åŠ¨æœåŠ¡
- âœ… é…ç½®Nginxåå‘ä»£ç†
- âœ… è¿è¡Œå¥åº·æ£€æŸ¥

#### æ­¥éª¤7: æµ‹è¯•éƒ¨ç½²

```bash
# æµ‹è¯•åç«¯å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# æµ‹è¯•æ£€æµ‹API
curl -X POST http://localhost:8000/api/v1/detect \
  -F "image=@/path/to/test-image.jpg"
```

#### æ­¥éª¤8: è®¿é—®åº”ç”¨

åœ¨æµè§ˆå™¨æ‰“å¼€:
```
http://<EC2-PUBLIC-IP>
```

---

## ğŸ“Š éƒ¨ç½²åæ£€æŸ¥æ¸…å•

### éªŒè¯æ‰€æœ‰æ¨¡å‹å·²åŠ è½½

```bash
# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker-compose logs backend | grep "model loaded"

# åº”è¯¥çœ‹åˆ°:
# âœ“ SBI model loaded successfully on cuda
# âœ“ DistilDIRE model loaded successfully on cuda
# âœ“ ChatGPT Vision model loaded successfully
# âœ“ Detection Service initialized:
#   - SBI: Active
#   - DistilDIRE: Active
#   - ChatGPT Vision: Active
```

### æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœä½¿ç”¨GPUå®ä¾‹ï¼‰

```bash
# æŸ¥çœ‹GPUçŠ¶æ€
nvidia-smi

# åº”è¯¥çœ‹åˆ°GPUè¢«PyTorchä½¿ç”¨
```

### æµ‹è¯•å®Œæ•´æµç¨‹

1. æ‰“å¼€æµè§ˆå™¨è®¿é—® `http://<EC2-PUBLIC-IP>`
2. ä¸Šä¼ ä¸€å¼ æµ‹è¯•å›¾ç‰‡
3. æŸ¥çœ‹ç»“æœï¼Œç¡®ä¿æ˜¾ç¤ºä¸‰ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
4. æ£€æŸ¥ `ensemble_mode` æ˜¯å¦ä¸º `"3_models_active"`

---

## ğŸ”§ å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1: æ¨¡å‹åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
docker-compose exec backend ls -lh /app/ml_models/deployment_package/models/sbi/
docker-compose exec backend ls -lh /app/ml_models/deployment_package/models/distildire/

# å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡æ–°ä¸Šä¼ å¹¶é‡å¯
docker-compose restart backend
```

### é—®é¢˜2: GPUä¸å¯ç”¨

```bash
# æ£€æŸ¥NVIDIAé©±åŠ¨
nvidia-smi

# å¦‚æœæŠ¥é”™ï¼Œå®‰è£…NVIDIA Docker runtime
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update && sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### é—®é¢˜3: å†…å­˜ä¸è¶³

```bash
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
docker stats

# å¦‚æœå†…å­˜ä¸è¶³ï¼Œæ·»åŠ swapç©ºé—´
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

### é—®é¢˜4: APIå“åº”æ…¢

- ç¡®ä¿ä½¿ç”¨GPUå®ä¾‹ (g4dnç³»åˆ—)
- æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹éƒ½åœ¨ä½¿ç”¨GPU
- è€ƒè™‘å‡çº§åˆ°æ›´å¤§çš„å®ä¾‹

---

## ğŸ’° æˆæœ¬ä¼˜åŒ–å»ºè®®

### å¼€å‘/æµ‹è¯•é˜¶æ®µ
- ä½¿ç”¨ `t3.xlarge` (CPU only) - ä¾¿å®œä½†æ…¢
- åªåœ¨å·¥ä½œæ—¶é—´è¿è¡Œï¼Œä¸‹ç­ååœæ­¢å®ä¾‹
- ä½¿ç”¨ Spot Instances å¯èŠ‚çœ70%æˆæœ¬

### ç”Ÿäº§ç¯å¢ƒ
- ä½¿ç”¨ `g4dn.xlarge` (GPU) - æ€§èƒ½å¥½
- è®¾ç½®Auto Scalingæ ¹æ®æµé‡è°ƒæ•´
- ä½¿ç”¨Reserved InstancesèŠ‚çœ40-60%

### åœæ­¢å®ä¾‹èŠ‚çœæˆæœ¬

```bash
# åœæ­¢å®ä¾‹ä½†ä¿ç•™æ•°æ®
aws ec2 stop-instances --instance-ids i-xxxxxxxxx

# é‡å¯å®ä¾‹
aws ec2 start-instances --instance-ids i-xxxxxxxxx
```

---

## ğŸ”’ å®‰å…¨åŠ å›ºï¼ˆå¯é€‰ï¼‰

### 1. å¯ç”¨HTTPSï¼ˆå¦‚æœæœ‰åŸŸåï¼‰

```bash
# å®‰è£…Certbot
sudo apt-get install -y certbot python3-certbot-nginx

# è·å–SSLè¯ä¹¦
sudo certbot --nginx -d your-domain.com

# æµ‹è¯•è‡ªåŠ¨ç»­æœŸ
sudo certbot renew --dry-run
```

### 2. é™åˆ¶SSHè®¿é—®

```bash
# åªå…è®¸ä½ çš„IPè®¿é—®SSH
aws ec2 authorize-security-group-ingress \
    --group-id sg-xxx \
    --protocol tcp --port 22 \
    --cidr YOUR-IP/32

# æ’¤é”€æ‰€æœ‰äººçš„SSHè®¿é—®
aws ec2 revoke-security-group-ingress \
    --group-id sg-xxx \
    --protocol tcp --port 22 \
    --cidr 0.0.0.0/0
```

### 3. ä½¿ç”¨AWS Secrets Managerå­˜å‚¨APIå¯†é’¥

```bash
# åˆ›å»ºsecret
aws secretsmanager create-secret \
    --name deepfake/openai-api-key \
    --secret-string "your-api-key"

# åœ¨ä»£ç ä¸­è¯»å–ï¼ˆéœ€è¦ä¿®æ”¹config.pyï¼‰
```

---

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹å®æ—¶æ—¥å¿—

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# åªæŸ¥çœ‹backendæ—¥å¿—
docker-compose logs -f backend

# æŸ¥çœ‹æœ€è¿‘100è¡Œ
docker-compose logs --tail=100 backend
```

### è®¾ç½®CloudWatchå‘Šè­¦

```bash
# CPUä½¿ç”¨ç‡è¶…è¿‡80%æ—¶å‘é€å‘Šè­¦
aws cloudwatch put-metric-alarm \
    --alarm-name deepfake-high-cpu \
    --alarm-description "CPU exceeds 80%" \
    --metric-name CPUUtilization \
    --namespace AWS/EC2 \
    --statistic Average \
    --period 300 \
    --threshold 80 \
    --comparison-operator GreaterThanThreshold \
    --dimensions Name=InstanceId,Value=i-xxx \
    --evaluation-periods 2 \
    --alarm-actions arn:aws:sns:region:account-id:topic-name
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. âœ… éƒ¨ç½²å®Œæˆå¹¶æµ‹è¯•é€šè¿‡
2. ğŸ“ é…ç½®åŸŸåå’ŒSSLè¯ä¹¦
3. ğŸ“Š è®¾ç½®ç›‘æ§å’Œå‘Šè­¦
4. ğŸ’° ä¼˜åŒ–æˆæœ¬ï¼ˆåœæœºç­–ç•¥ï¼‰
5. ğŸ”’ åŠ å¼ºå®‰å…¨é…ç½®
6. ğŸ“ˆ æ ¹æ®ä½¿ç”¨æƒ…å†µè°ƒæ•´å®ä¾‹å¤§å°

---

**åˆ›å»ºæ—¶é—´**: 2026-01-06
**é€‚ç”¨ç‰ˆæœ¬**: v1.0
**é¢„è®¡éƒ¨ç½²æ—¶é—´**: 30-45åˆ†é’Ÿ
